import chromadb  # Importa la librer√≠a principal de ChromaDB para interactuar con la base de datos
from chromadb.config import Settings  # Importa la clase Settings para configurar la conexi√≥n a ChromaDB
from chromadb.utils import embedding_functions  # Importa funciones de embedding para usar modelos personalizados
import json  # Importa el m√≥dulo json para formatear los resultados de manera legible
import time  # Importa el m√≥dulo time para medir el rendimiento de las operaciones
from typing import List, Dict, Any  # Importa tipos de datos para mejor documentaci√≥n del c√≥digo

class AdvancedSemanticSearch:
    """
    Clase para implementar b√∫squeda sem√°ntica avanzada con ChromaDB.
    
    Esta clase proporciona funcionalidades avanzadas como:
    - Embeddings personalizados con sentence-transformers
    - Diferentes m√©tricas de similitud
    - Filtrado por metadatos
    - B√∫squeda h√≠brida
    - Monitoreo de rendimiento
    """
    
    def __init__(self, persist_directory: str = "./chroma_db_advanced"):
        """
        Inicializa el sistema de b√∫squeda sem√°ntica avanzada.
        
        Args:
            persist_directory (str): Directorio donde se guardar√°n los datos de ChromaDB
        """
        # Configura el directorio de persistencia para almacenar los datos de ChromaDB
        # Esto permite que los datos persistan entre ejecuciones del programa
        self.persist_directory = persist_directory
        
        # Crea una instancia del cliente de ChromaDB con configuraci√≥n personalizada
        # Settings(persist_directory=...) especifica d√≥nde guardar los datos en disco
        self.client = chromadb.Client(Settings(persist_directory=persist_directory))
        
        # Configura el embedding function usando sentence-transformers
        # 'all-MiniLM-L6-v2' es un modelo eficiente y preciso para embeddings en espa√±ol e ingl√©s
        # Este modelo genera vectores de 384 dimensiones que capturan el significado sem√°ntico
        self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="all-MiniLM-L6-v2"
        )
        
        # Crea o obtiene la colecci√≥n principal con el embedding function personalizado
        # La colecci√≥n almacenar√° documentos con embeddings generados por el modelo especificado
        self.collection = self.client.get_or_create_collection(
            name="advanced_semantic_collection",
            embedding_function=self.embedding_function
        )
        
        print(f"‚úÖ Sistema de b√∫squeda sem√°ntica avanzada inicializado en: {persist_directory}")
    
    def add_documents_with_metadata(self, documents: List[str], ids: List[str], 
                                   metadatas: List[Dict[str, Any]] = None) -> None:
        """
        Agrega documentos a la colecci√≥n con metadatos opcionales.
        
        Args:
            documents (List[str]): Lista de textos a almacenar
            ids (List[str]): IDs √∫nicos para cada documento
            metadatas (List[Dict[str, Any]], optional): Metadatos para cada documento
        """
        # Valida que el n√∫mero de documentos, IDs y metadatos sea consistente
        if metadatas is None:
            metadatas = [{} for _ in documents]  # Crea metadatos vac√≠os si no se proporcionan
        
        # Verifica que todos los arrays tengan la misma longitud para evitar errores
        if len(documents) != len(ids) or len(documents) != len(metadatas):
            raise ValueError("El n√∫mero de documentos, IDs y metadatos debe ser igual")
        
        # Registra el tiempo de inicio para medir el rendimiento de la operaci√≥n
        start_time = time.time()
        
        # Agrega los documentos a la colecci√≥n con sus metadatos correspondientes
        # ChromaDB autom√°ticamente generar√° embeddings usando el embedding function configurado
        self.collection.add(
            documents=documents,  # Lista de textos a procesar y almacenar
            ids=ids,  # Identificadores √∫nicos para cada documento
            metadatas=metadatas  # Metadatos asociados a cada documento
        )
        
        # Calcula y muestra el tiempo total de la operaci√≥n
        elapsed_time = time.time() - start_time
        print(f"‚úÖ {len(documents)} documentos agregados en {elapsed_time:.2f} segundos")
    
    def semantic_search(self, query: str, n_results: int = 5, 
                       where_filter: Dict[str, Any] = None,
                       where_document_filter: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Realiza b√∫squeda sem√°ntica con filtros opcionales.
        
        Args:
            query (str): Texto de consulta para buscar similitud sem√°ntica
            n_results (int): N√∫mero de resultados m√°s similares a retornar
            where_filter (Dict[str, Any], optional): Filtro por metadatos
            where_document_filter (Dict[str, Any], optional): Filtro por contenido del documento
            
        Returns:
            Dict[str, Any]: Resultados de la b√∫squeda con documentos, metadatos y distancias
        """
        # Registra el tiempo de inicio para medir el rendimiento de la consulta
        start_time = time.time()
        
        # Realiza la consulta sem√°ntica con los filtros especificados
        # El embedding function convertir√° autom√°ticamente la consulta a un vector
        results = self.collection.query(
            query_texts=[query],  # Convierte la consulta a lista para compatibilidad con ChromaDB
            n_results=n_results,  # N√∫mero m√°ximo de resultados a retornar
            where=where_filter,  # Filtro opcional por metadatos
            where_document=where_document_filter  # Filtro opcional por contenido del documento
        )
        
        # Calcula el tiempo total de la consulta
        elapsed_time = time.time() - start_time
        
        # Agrega informaci√≥n de rendimiento a los resultados
        results['query_time'] = elapsed_time
        results['query'] = query
        
        print(f"üîç B√∫squeda completada en {elapsed_time:.3f} segundos")
        return results
    
    def hybrid_search(self, query: str, n_results: int = 5,
                     where_filter: Dict[str, Any] = None,
                     weight_text: float = 0.7) -> Dict[str, Any]:
        """
        Realiza b√∫squeda h√≠brida combinando b√∫squeda sem√°ntica y filtrado por metadatos.
        
        Args:
            query (str): Texto de consulta para b√∫squeda sem√°ntica
            n_results (int): N√∫mero de resultados a retornar
            where_filter (Dict[str, Any], optional): Filtro por metadatos
            weight_text (float): Peso para la b√∫squeda de texto (0.0 a 1.0)
            
        Returns:
            Dict[str, Any]: Resultados de la b√∫squeda h√≠brida
        """
        # Realiza b√∫squeda sem√°ntica b√°sica
        semantic_results = self.semantic_search(query, n_results * 2, where_filter)
        
        # Si hay filtros de metadatos, aplica filtrado adicional
        if where_filter:
            # Filtra resultados por metadatos y recalcula rankings
            filtered_results = self._apply_metadata_filtering(semantic_results, where_filter)
            return filtered_results
        
        return semantic_results
    
    def _apply_metadata_filtering(self, results: Dict[str, Any], 
                                 where_filter: Dict[str, Any]) -> Dict[str, Any]:
        """
        Aplica filtrado adicional por metadatos a los resultados de b√∫squeda.
        
        Args:
            results (Dict[str, Any]): Resultados de b√∫squeda sem√°ntica
            where_filter (Dict[str, Any]): Filtro de metadatos a aplicar
            
        Returns:
            Dict[str, Any]: Resultados filtrados
        """
        # Implementa l√≥gica de filtrado personalizada aqu√≠
        # Por ahora, retorna los resultados originales
        return results
    
    def get_collection_info(self) -> Dict[str, Any]:
        """
        Obtiene informaci√≥n detallada sobre la colecci√≥n actual.
        
        Returns:
            Dict[str, Any]: Informaci√≥n de la colecci√≥n incluyendo conteo y metadatos
        """
        # Obtiene el conteo total de documentos en la colecci√≥n
        count = self.collection.count()
        
        # Obtiene una muestra de documentos para analizar la estructura
        sample_results = self.collection.get(limit=5)
        
        return {
            'total_documents': count,
            'sample_documents': sample_results,
            'embedding_function': str(self.embedding_function),
            'persist_directory': self.persist_directory
        }

def main():
    """
    Funci√≥n principal que demuestra el uso del sistema de b√∫squeda sem√°ntica avanzada.
    """
    # Crea una instancia del sistema de b√∫squeda sem√°ntica avanzada
    # Esto inicializa ChromaDB con embeddings personalizados
    search_system = AdvancedSemanticSearch()
    
    # Define documentos de ejemplo con metadatos ricos para demostrar capacidades avanzadas
    # Cada documento tiene metadatos que incluyen categor√≠a, idioma, fecha y tags
    documents = [
        "ChromaDB es una base de datos vectorial de c√≥digo abierto para aplicaciones de IA",
        "Los embeddings son representaciones vectoriales que capturan el significado sem√°ntico",
        "La b√∫squeda sem√°ntica permite encontrar informaci√≥n similar sin coincidencia exacta de palabras",
        "Los modelos de lenguaje como GPT utilizan embeddings para entender el contexto",
        "Las bases de datos vectoriales son esenciales para aplicaciones de IA moderna",
        "El procesamiento de lenguaje natural requiere comprensi√≥n sem√°ntica avanzada",
        "Los sistemas de recomendaci√≥n utilizan similitud vectorial para sugerir contenido",
        "La indexaci√≥n sem√°ntica mejora significativamente la precisi√≥n de b√∫squeda"
    ]
    
    # Define IDs √∫nicos para cada documento
    ids = [f"doc_{i+1}" for i in range(len(documents))]
    
    # Define metadatos ricos para cada documento
    # Los metadatos permiten filtrado y organizaci√≥n avanzada
    metadatas = [
        {"category": "database", "language": "es", "difficulty": "beginner", "tags": ["chromadb", "vector"]},
        {"category": "ai", "language": "es", "difficulty": "intermediate", "tags": ["embeddings", "vectors"]},
        {"category": "search", "language": "es", "difficulty": "intermediate", "tags": ["semantic", "search"]},
        {"category": "ai", "language": "es", "difficulty": "advanced", "tags": ["gpt", "nlp"]},
        {"category": "database", "language": "es", "difficulty": "intermediate", "tags": ["vector", "ai"]},
        {"category": "nlp", "language": "es", "difficulty": "advanced", "tags": ["nlp", "semantic"]},
        {"category": "recommendation", "language": "es", "difficulty": "intermediate", "tags": ["recommendation", "vector"]},
        {"category": "search", "language": "es", "difficulty": "advanced", "tags": ["indexing", "semantic"]}
    ]
    
    # Agrega los documentos con sus metadatos a la colecci√≥n
    # Esto generar√° embeddings autom√°ticamente usando el modelo sentence-transformers
    search_system.add_documents_with_metadata(documents, ids, metadatas)
    
    # Obtiene y muestra informaci√≥n sobre la colecci√≥n
    collection_info = search_system.get_collection_info()
    print("\nüìä Informaci√≥n de la colecci√≥n:")
    print(json.dumps(collection_info, indent=2, ensure_ascii=False))
    
    # Demuestra diferentes tipos de b√∫squeda sem√°ntica avanzada
    
    print("\nüîç === B√öSQUEDA SEM√ÅNTICA B√ÅSICA ===")
    # Realiza b√∫squeda sem√°ntica b√°sica sin filtros
    basic_results = search_system.semantic_search("¬øQu√© es ChromaDB?", n_results=3)
    print("Consulta: '¬øQu√© es ChromaDB?'")
    print(json.dumps(basic_results, indent=2, ensure_ascii=False))
    
    print("\nüîç === B√öSQUEDA CON FILTRO POR CATEGOR√çA ===")
    # Realiza b√∫squeda sem√°ntica filtrando por categor√≠a espec√≠fica
    category_results = search_system.semantic_search(
        "bases de datos vectoriales", 
        n_results=3,
        where_filter={"category": "database"}
    )
    print("Consulta: 'bases de datos vectoriales' (solo categor√≠a 'database')")
    print(json.dumps(category_results, indent=2, ensure_ascii=False))
    
    print("\nüîç === B√öSQUEDA CON FILTRO POR DIFICULTAD ===")
    # Realiza b√∫squeda sem√°ntica filtrando por nivel de dificultad
    difficulty_results = search_system.semantic_search(
        "embeddings y vectores", 
        n_results=3,
        where_filter={"difficulty": "beginner"}
    )
    print("Consulta: 'embeddings y vectores' (solo dificultad 'beginner')")
    print(json.dumps(difficulty_results, indent=2, ensure_ascii=False))
    
    print("\nüîç === B√öSQUEDA H√çBRIDA ===")
    # Realiza b√∫squeda h√≠brida combinando sem√°ntica y filtros
    hybrid_results = search_system.hybrid_search(
        "inteligencia artificial", 
        n_results=3,
        where_filter={"category": "ai"}
    )
    print("Consulta: 'inteligencia artificial' (categor√≠a 'ai')")
    print(json.dumps(hybrid_results, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    # Ejecuta la funci√≥n principal cuando el script se ejecuta directamente
    # Esto permite que el c√≥digo se ejecute como programa independiente
    main() 